{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912beb6a",
   "metadata": {},
   "source": [
    "# VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f95d49",
   "metadata": {},
   "source": [
    "| DB | Description |\n",
    "|----|-------------|\n",
    "| Regulation DB | 회사 내규 또는 법률에 대한 VectorDB |\n",
    "| Space DB | 사옥 내 정보, 인사 조직도 및 연락처 등 정보에 대한 VectorDB |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8284c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc63d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 📌 VectorDB 파이프라인 (Jupyter Notebook 테스트용)\n",
    "# - PDF 텍스트 + 이미지 Embedding\n",
    "# - FAISS 기반 VectorDB 구축\n",
    "# - 문서 목록 조회 / 삭제 기능 포함\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from io import BytesIO\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "import faiss\n",
    "\n",
    "from langchain.vectorstores import FAISS as LangChainFAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ 설정\n",
    "# -----------------------------------------\n",
    "\n",
    "DATA_DIRS = {\n",
    "    \"regulation\": {\n",
    "        \"raw\": \"./data/raw/regulation\",\n",
    "        \"processed\": \"./data/processed/regulation\",\n",
    "        \"embeddings\": \"./data/embeddings/regulation\"\n",
    "    },\n",
    "    \"space\": {\n",
    "        \"raw\": \"./data/raw/space\",\n",
    "        \"processed\": \"./data/processed/space\",\n",
    "        \"embeddings\": \"./data/embeddings/space\"\n",
    "    }\n",
    "}\n",
    "\n",
    "VECTORDB_DIRS = {\n",
    "    \"regulation\": \"./vectordb/regulation_db\",\n",
    "    \"space\": \"./vectordb/space_db\"\n",
    "}\n",
    "\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# 문장 임베딩용 모델 (빠른 사용을 위해 미리 로드)\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ PDF 텍스트 추출\n",
    "# -----------------------------------------\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    texts = []\n",
    "    for page in doc:\n",
    "        texts.append(page.get_text())\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ PDF 이미지 추출\n",
    "# -----------------------------------------\n",
    "\n",
    "def extract_images_from_pdf(pdf_path: str) -> List[Image.Image]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page in doc:\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image = Image.open(BytesIO(base_image[\"image\"]))\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ 이미지 → 임베딩 변환\n",
    "# -----------------------------------------\n",
    "\n",
    "def image_to_embedding(image: Image.Image) -> np.ndarray:\n",
    "    image = image.resize((64, 64)).convert(\"RGB\")\n",
    "    arr = np.array(image).flatten() / 255.0\n",
    "    return arr[:384] if arr.size >= 384 else np.pad(arr, (0, 384 - arr.size))\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ VectorDB 구축\n",
    "# -----------------------------------------\n",
    "\n",
    "def build_vectordb(target: str):\n",
    "    data_info = DATA_DIRS[target]\n",
    "    vectordb_dir = VECTORDB_DIRS[target]\n",
    "\n",
    "    os.makedirs(data_info[\"processed\"], exist_ok=True)\n",
    "    os.makedirs(data_info[\"embeddings\"], exist_ok=True)\n",
    "    os.makedirs(vectordb_dir, exist_ok=True)\n",
    "\n",
    "    index = faiss.IndexFlatL2(384)\n",
    "    docs = []\n",
    "\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "    files = list(Path(data_info[\"raw\"]).glob(\"*.pdf\"))\n",
    "\n",
    "    if len(files) == 0:\n",
    "        print(f\"[경고] {data_info['raw']} 경로에 PDF 파일이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    for file in tqdm(files, desc=f\"Processing {target} PDFs\"):\n",
    "\n",
    "        text = extract_text_from_pdf(str(file))\n",
    "        text_file = Path(data_info[\"processed\"]) / (file.stem + \".txt\")\n",
    "        text_file.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "        text_embedding = embedding_model.embed_query(text)\n",
    "        emb_path = Path(data_info[\"embeddings\"]) / (file.stem + \"_text.npy\")\n",
    "        np.save(emb_path, text_embedding)\n",
    "\n",
    "        index.add(np.array([text_embedding], dtype=np.float32))\n",
    "        docs.append(Document(page_content=text, metadata={\"source\": str(file), \"type\": \"text\"}))\n",
    "\n",
    "        images = extract_images_from_pdf(str(file))\n",
    "        for idx, img in enumerate(tqdm(images, desc=f\"{file.stem} 이미지 처리\")):\n",
    "            img_embedding = image_to_embedding(img)\n",
    "            emb_path = Path(data_info[\"embeddings\"]) / f\"{file.stem}_img{idx}.npy\"\n",
    "            np.save(emb_path, img_embedding)\n",
    "\n",
    "            index.add(np.array([img_embedding], dtype=np.float32))\n",
    "            docs.append(Document(page_content=f\"Image from {file.stem} (index {idx})\", metadata={\"source\": str(file), \"type\": f\"image_{idx}\"}))\n",
    "\n",
    "    faiss.write_index(index, os.path.join(vectordb_dir, \"index.faiss\"))\n",
    "    index_to_docstore_id = {i: str(i) for i in range(len(docs))}\n",
    "    docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(docs)})\n",
    "\n",
    "    lc_faiss = LangChainFAISS(embedding_model, index, docstore, index_to_docstore_id)\n",
    "    lc_faiss.save_local(vectordb_dir)\n",
    "\n",
    "    print(f\"✅ Saved VectorDB to {vectordb_dir}\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ 문서 추가\n",
    "# -----------------------------------------\n",
    "\n",
    "def add_document_to_vectordb(pdf_path: str, target: str, security_level: str = \"중\"):\n",
    "    vectordb_dir = VECTORDB_DIRS[target]\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    vectordb = LangChainFAISS.load_local(vectordb_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    text_embedding = embedding_model.embed_query(text)\n",
    "\n",
    "    text_doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\"source\": pdf_path, \"type\": \"text\", \"security_level\": security_level}\n",
    "    )\n",
    "\n",
    "    vectordb.index.add(np.array([text_embedding], dtype=np.float32))\n",
    "    new_docstore_id = str(len(vectordb.docstore._dict))\n",
    "    vectordb.docstore._dict[new_docstore_id] = text_doc\n",
    "    vectordb.index_to_docstore_id[vectordb.index.ntotal - 1] = new_docstore_id\n",
    "\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    for idx, img in enumerate(tqdm(images, desc=f\"{Path(pdf_path).stem} 이미지 추가\")):\n",
    "        img_embedding = image_to_embedding(img)\n",
    "        img_doc = Document(\n",
    "            page_content=f\"Image from {Path(pdf_path).stem} (index {idx})\",\n",
    "            metadata={\"source\": pdf_path, \"type\": f\"image_{idx}\", \"security_level\": security_level}\n",
    "        )\n",
    "\n",
    "        vectordb.index.add(np.array([img_embedding], dtype=np.float32))\n",
    "        new_docstore_id = str(len(vectordb.docstore._dict))\n",
    "        vectordb.docstore._dict[new_docstore_id] = img_doc\n",
    "        vectordb.index_to_docstore_id[vectordb.index.ntotal - 1] = new_docstore_id\n",
    "\n",
    "    vectordb.save_local(vectordb_dir)\n",
    "\n",
    "    print(f\"✅ {pdf_path} 추가 완료 (보안등급: {security_level})\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ 문서 목록 조회\n",
    "# -----------------------------------------\n",
    "\n",
    "def list_vectordb(vectordb_dir: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    VectorDB 내 문서 목록을 조회합니다. (파일명 + 보안등급만 반환, 중복 제거)\n",
    "\n",
    "    Returns:\n",
    "        List of (파일명, 보안등급)\n",
    "    \"\"\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    vectordb = LangChainFAISS.load_local(vectordb_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    docs = vectordb.docstore._dict.values()\n",
    "\n",
    "    summary = {}\n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get(\"source\", \"unknown\")\n",
    "        security_level = doc.metadata.get(\"security_level\", \"중\")\n",
    "\n",
    "        file_name = Path(source).name\n",
    "        summary[file_name] = security_level  # 같은 파일명이면 덮어씀 (보안등급은 동일함)\n",
    "\n",
    "    return list(summary.items())\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ 특정 문서 삭제\n",
    "# -----------------------------------------\n",
    "\n",
    "def delete_document_from_vectordb(target: str, doc_source_name: str):\n",
    "    vectordb_dir = VECTORDB_DIRS[target]\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    vectordb = LangChainFAISS.load_local(vectordb_dir, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    remaining_docs = []\n",
    "    delete_docs = []\n",
    "\n",
    "    for doc in vectordb.docstore._dict.values():\n",
    "        source = doc.metadata.get(\"source\", \"\")\n",
    "        if doc_source_name in source:\n",
    "            delete_docs.append(doc)\n",
    "        else:\n",
    "            remaining_docs.append(doc)\n",
    "\n",
    "    if not delete_docs:\n",
    "        print(f\"❗ 삭제 대상 문서를 찾을 수 없습니다: {doc_source_name}\")\n",
    "        return\n",
    "\n",
    "    print(f\"✅ {len(delete_docs)}개 문서 삭제\")\n",
    "\n",
    "    new_index = faiss.IndexFlatL2(384)\n",
    "    new_docstore = {}\n",
    "    new_index_to_docstore_id = {}\n",
    "\n",
    "    for i, doc in enumerate(remaining_docs):\n",
    "        content = doc.page_content\n",
    "        doc_type = doc.metadata.get(\"type\", \"unknown\")\n",
    "\n",
    "        if doc_type.startswith(\"image\"):\n",
    "            arr = image_to_embedding(Image.new(\"RGB\", (64, 64)))\n",
    "        else:\n",
    "            arr = embedding_model.embed_query(content)\n",
    "\n",
    "        new_index.add(np.array([arr], dtype=np.float32))\n",
    "        new_docstore[str(i)] = doc\n",
    "        new_index_to_docstore_id[new_index.ntotal - 1] = str(i)\n",
    "\n",
    "    new_vectordb = LangChainFAISS(embedding_model, new_index, InMemoryDocstore(new_docstore), new_index_to_docstore_id)\n",
    "    new_vectordb.save_local(vectordb_dir)\n",
    "\n",
    "    print(f\"✅ VectorDB 재구성 완료 ({vectordb_dir})\")\n",
    "\n",
    "# -----------------------------------------\n",
    "# ✅ VectorDB 전체 삭제\n",
    "# -----------------------------------------\n",
    "\n",
    "def delete_vectordb(vectordb_dir: str):\n",
    "    if os.path.exists(vectordb_dir):\n",
    "        shutil.rmtree(vectordb_dir)\n",
    "        print(f\"✅ {vectordb_dir} 전체 삭제 완료\")\n",
    "    else:\n",
    "        print(\"❗ 삭제할 VectorDB가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080d4ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1] VectorDB 구축 테스트\n",
      "VectorDB가 없거나 index.faiss가 없으므로 새로 구축합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_document 이미지 처리: 100%|██████████| 10842/10842 [00:16<00:00, 650.91it/s]\n",
      "근로기준법(법률)(제20520호)(20250223) 이미지 처리: 100%|██████████| 1/1 [00:00<00:00, 142.89it/s]\n",
      "Processing regulation PDFs: 100%|██████████| 2/2 [00:27<00:00, 13.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved VectorDB to ./vectordb/regulation_db\n"
     ]
    }
   ],
   "source": [
    "def test_vectordb_flow():\n",
    "    target = \"regulation\"  # 테스트할 target 설정\n",
    "    vectordb_dir = VECTORDB_DIRS.get(target)\n",
    "    index_file = os.path.join(vectordb_dir, \"index.faiss\")\n",
    "\n",
    "    if vectordb_dir is None:\n",
    "        print(f\"❗ 대상 '{target}' 이(가) VECTORDB_DIRS에 등록되어 있지 않습니다.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n[Step 1] VectorDB 구축 테스트\")\n",
    "    if not os.path.exists(index_file):\n",
    "        print(\"VectorDB가 없거나 index.faiss가 없으므로 새로 구축합니다.\")\n",
    "        build_vectordb(target)\n",
    "    else:\n",
    "        print(\"✅ 이미 구축된 VectorDB가 존재합니다.\")\n",
    "\n",
    "    # print(\"\\n[Step 2] 문서 추가 테스트 (보안등급 상으로 추가)\")\n",
    "    # test_pdf_path = \"./data/raw/regulation/test_document.pdf\"\n",
    "\n",
    "    # if not os.path.exists(test_pdf_path):\n",
    "    #     print(\"❗ 테스트용 PDF 파일이 존재하지 않습니다. 경로: './data/raw/regulation/test_document.pdf'\")\n",
    "    #     return\n",
    "\n",
    "    # add_document_to_vectordb(test_pdf_path, target, security_level=\"상\")\n",
    "\n",
    "    # print(\"\\n[Step 3] VectorDB 문서 목록 조회 (보안등급 확인)\")\n",
    "    # entries = list_vectordb(vectordb_dir)\n",
    "    # if not entries:\n",
    "    #     print(\"❗ VectorDB에 문서가 없습니다.\")\n",
    "    # else:\n",
    "    #     for file_name, security_level in entries:\n",
    "    #         print(f\"{file_name} | 보안등급: {security_level}\")\n",
    "\n",
    "    # print(\"\\n[Step 4] 특정 문서 삭제 테스트 (test_document.pdf)\")\n",
    "    # delete_document_from_vectordb(target, \"test_document.pdf\")\n",
    "\n",
    "    # print(\"\\n[Step 5] VectorDB 문서 목록 재조회 (삭제 결과 확인)\")\n",
    "    # entries_after_delete = list_vectordb(vectordb_dir)\n",
    "    # if not entries_after_delete:\n",
    "    #     print(\"✅ 모든 문서가 삭제되어 VectorDB가 비어있습니다.\")\n",
    "    # else:\n",
    "    #     for file_name, security_level in entries_after_delete:\n",
    "    #         print(f\"{file_name} | 보안등급: {security_level}\")\n",
    "\n",
    "    # print(\"\\n[Step 6] VectorDB 전체 삭제 테스트\")\n",
    "    # delete_vectordb(vectordb_dir)\n",
    "\n",
    "    # if not os.path.exists(vectordb_dir):\n",
    "    #     print(\"✅ VectorDB 전체 삭제 완료\")\n",
    "    # else:\n",
    "    #     print(\"❗ VectorDB 전체 삭제 실패\")\n",
    "        \n",
    "test_vectordb_flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04bf4a",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28993dd8",
   "metadata": {},
   "source": [
    "| Agent | Description | DB |\n",
    "|-------|-------------|----|\n",
    "| Regulation Agent | 회사 내규 또는 법률에 대해 답변하는 Agent로, Regulation DB 기반 RAG 형식으로 구축 | Regulation DB |\n",
    "| Space Agent | 사옥 내 정보, 인사 조직도 및 연락처 등 질문에 대해 답변하는 Agent로, Space DB 기반 RAG 형식으로 구축 | Space DB |\n",
    "| Worker Agent | 사용자의 질문에 대하여 이전 Reference 자료 또는 양식(Template)을 찾아주는 Agent로, 사내 DB API를 호출하여 답변 | 사내 DB API |\n",
    "| General Agent | 위 내용 외의 일반적인 질문(ex. 날씨 등)에 대해 답변하는 Agent | 외부 일반 데이터 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89c5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a060e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key 인증 성공! 사용 가능한 모델:\n",
      "- gpt-4o-audio-preview-2024-12-17\n",
      "- dall-e-3\n",
      "- dall-e-2\n",
      "- gpt-4o-audio-preview-2024-10-01\n",
      "- gpt-4-turbo-preview\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"✅ API Key 인증 성공! 사용 가능한 모델:\")\n",
    "    for model in models.data[:5]:\n",
    "        print(\"-\", model.id)\n",
    "except Exception as e:\n",
    "    print(\"❌ API Key 인증 실패:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d20a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Supervisor 최종 Intent]: space\n",
      "\n",
      "=== 최종 응답 ===\n",
      "사내 카페는 지상 1층에 위치해 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from typing import TypedDict, Optional, Literal\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Load environment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(\"OpenAI API Key:\", OPENAI_API_KEY)\n",
    "\n",
    "# -----------------------\n",
    "# VectorDB 로드 (FAISS)\n",
    "# -----------------------\n",
    "\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "regulation_vectordb = FAISS.load_local(\"./vectordb/regulation_db\", embeddings, index_name=\"index\", allow_dangerous_deserialization=True)\n",
    "space_vectordb = FAISS.load_local(\"./vectordb/space_db\", embeddings, index_name=\"index\", allow_dangerous_deserialization=True)\n",
    "\n",
    "# -----------------------\n",
    "# Company API Client\n",
    "# -----------------------\n",
    "\n",
    "class CompanyAPIClient:\n",
    "    def __init__(self):\n",
    "        self.templates = {\n",
    "            \"회의록\": \"회의록 양식: - 회의 일시 - 장소 - 참석자 - 주요 안건 - 논의 내용 - 결론 및 조치 사항\",\n",
    "            \"출장 보고서\": \"출장 보고서 양식: - 출장지 - 출장 기간 - 출장 목적 - 주요 활동 - 결과 및 향후 계획\",\n",
    "            \"경조사 신청\": \"경조사 신청서 양식: - 신청인 - 관계 - 경조사 종류 - 일시 및 장소 - 기타 사항\",\n",
    "        }\n",
    "\n",
    "    def search_templates(self, query: str) -> Optional[str]:\n",
    "        for keyword, template in self.templates.items():\n",
    "            if keyword in query:\n",
    "                return template\n",
    "        return None\n",
    "\n",
    "api_client = CompanyAPIClient()\n",
    "\n",
    "# -----------------------\n",
    "# LLM 초기화\n",
    "# -----------------------\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# -----------------------\n",
    "# Agents 정의\n",
    "# -----------------------\n",
    "\n",
    "def regulation_agent(user_input: str) -> str:\n",
    "    docs = regulation_vectordb.similarity_search(user_input, k=3)\n",
    "    context = \"\\n\".join([d.page_content for d in docs])\n",
    "    prompt = f\"내규 문서:\\n{context}\\n\\n질문: {user_input}\"\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "def space_agent(user_input: str) -> str:\n",
    "    docs = space_vectordb.similarity_search(user_input, k=3)\n",
    "    context = \"\\n\".join([d.page_content for d in docs])\n",
    "    prompt = f\"사옥 문서:\\n{context}\\n\\n질문: {user_input}\"\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "def worker_agent(user_input: str) -> str:\n",
    "    template = api_client.search_templates(user_input)\n",
    "    if template:\n",
    "        return f\"Template 추천:\\n\\n{template}\"\n",
    "    else:\n",
    "        return llm.invoke(f\"적절한 양식을 찾을 수 없습니다. 대신 일반 가이드를 작성하세요.\\n\\n{user_input}\").content\n",
    "\n",
    "def general_agent(user_input: str) -> str:\n",
    "    return llm.invoke(user_input).content\n",
    "\n",
    "# -----------------------\n",
    "# Agent Mapping\n",
    "# -----------------------\n",
    "\n",
    "AGENT_MAP = {\n",
    "    \"regulation\": regulation_agent,\n",
    "    \"space\": space_agent,\n",
    "    \"worker\": worker_agent,\n",
    "    \"general\": general_agent,\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# LangGraph 상태 정의\n",
    "# -----------------------\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    user_input: str\n",
    "    intent: Optional[Literal[\"regulation\", \"space\", \"worker\", \"general\"]]\n",
    "    response: Optional[str]\n",
    "    next_node: Optional[str]\n",
    "\n",
    "# -----------------------\n",
    "# Hybrid Supervisor (VectorDB + LLM)\n",
    "# -----------------------\n",
    "\n",
    "def supervisor_agent(state: AgentState) -> AgentState:\n",
    "    user_input = state[\"user_input\"]\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "                    너는 사용자의 질문을 다음 4개 Intent 중 하나로 분류하는 에이전트이다.\n",
    "\n",
    "                    Intent 종류:\n",
    "\n",
    "                    - regulation: 회사 내규, 법률, 인사, 근태, 연차, 휴가, 경조사 등 규정이나 정책에 관한 질문\n",
    "                    - space: 사옥, 조직도, 연락처, 좌석, 위치, 시설, 회의실 등 공간과 관련된 질문\n",
    "                    - worker: 업무 처리 방법, 업무 양식, 템플릿 등 형식이나 절차와 관련된 질문\n",
    "                    - general: 위에 해당하지 않는 일반적인 질문 (예: 날씨, 일상 대화, 회사와 관련 없는 질문 등)\n",
    "\n",
    "                    규칙:\n",
    "\n",
    "                    1. 반드시 위 4개 중 하나만 소문자로 정확히 골라서 답변하라.\n",
    "                    2. 질문이 규정이나 인사 관련이면 regulation 으로 분류하라.\n",
    "                    3. 질문이 사옥이나 공간 정보 관련이면 space 으로 분류하라.\n",
    "                    4. 질문이 업무 양식이나 절차 관련이면 worker 로 분류하라.\n",
    "                    5. 어떤 것도 아니거나 일상/일반적 질문이면 general 로 분류하라.\n",
    "                    6. 그 외는 절대 다른 단어를 사용하지 말고 위 4개 중 하나로만 답하라.\n",
    "\n",
    "                    질문: {input}\n",
    "                    답변 (intent 중 하나만): \n",
    "                    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    chain = prompt | llm | (lambda x: x.content.strip().lower())\n",
    "    intent = chain.invoke({\"input\": user_input})\n",
    "\n",
    "    print(f\"[Supervisor 최종 Intent]: {intent}\")\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"intent\": intent,\n",
    "        \"next_node\": intent\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 공통 Agent Executor\n",
    "# -----------------------\n",
    "\n",
    "def common_agent_executor(state: AgentState) -> AgentState:\n",
    "    agent_name = state[\"next_node\"]\n",
    "    user_input = state[\"user_input\"]\n",
    "\n",
    "    agent = AGENT_MAP.get(agent_name)\n",
    "\n",
    "    if agent is None:\n",
    "        result = \"적절한 Agent가 없습니다.\"\n",
    "    else:\n",
    "        result = agent(user_input)\n",
    "\n",
    "    return {**state, \"response\": result}\n",
    "\n",
    "# -----------------------\n",
    "# Graph 구성 (START → Supervisor → Executor → END)\n",
    "# -----------------------\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"supervisor\", supervisor_agent)\n",
    "graph.add_node(\"agent_executor\", common_agent_executor)\n",
    "\n",
    "graph.add_edge(START, \"supervisor\")\n",
    "graph.add_conditional_edges(\"supervisor\", lambda state: state[\"next_node\"], {\n",
    "    \"regulation\": \"agent_executor\",\n",
    "    \"space\": \"agent_executor\",\n",
    "    \"worker\": \"agent_executor\",\n",
    "    \"general\": \"agent_executor\",\n",
    "})\n",
    "graph.add_edge(\"agent_executor\", END)\n",
    "\n",
    "runnable = graph.compile()\n",
    "\n",
    "# -----------------------\n",
    "# 테스트 실행\n",
    "# -----------------------\n",
    "\n",
    "inputs = {\"user_input\": \"사내 카페 몇 층에 있나요?\"}\n",
    "\n",
    "result = runnable.invoke(inputs)\n",
    "\n",
    "print(\"\\n=== 최종 응답 ===\")\n",
    "print(result[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
